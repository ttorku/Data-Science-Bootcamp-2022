# -*- coding: utf-8 -*-
"""businescontrol.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_gSuRSZ-7Amu7kyMhRi-gwyPUzPrhZjB
"""

!pip install faker

from faker import Faker
import random
import pandas as pd

# Initialize Faker library
fake = Faker()

# Define a list of common business activities and obligations
activities = [
    ["Purchase order is issued", "Goods are delivered", "Invoice is received", "Payment is made"],
    ["Order is placed", "Items are shipped", "Bill is sent", "Payment is processed"],
    ["Contract is signed", "Work is started", "Work is completed", "Payment is received"],
    ["Proposal is submitted", "Proposal is accepted", "Work is initiated", "Work is delivered", "Payment is done"],
]

obligations = [
    "Ensure payment is made after goods are delivered",
    "Ensure work is started after contract is signed",
    "Ensure payment is done after work is delivered",
]

# Define number of examples
num_examples = 1000

# Define a function to generate a single example
def generate_example():
    # Select two different business processes that share the same obligation
    bp1, bp2 = random.sample(activities, 2)

    # Randomly select an obligation
    obligation = random.choice(obligations)

    return bp1, bp2, obligation

# Generate the synthetic data
data = [generate_example() for _ in range(num_examples)]

# Convert the data to a DataFrame and save it to a CSV file
df = pd.DataFrame(data, columns=["Business Process 1", "Business Process 2", "Obligation"])
df.to_csv("synthetic_data.csv", index=False)

df.head()

import nltk
import string
from nltk.tokenize import word_tokenize

# Download the punkt tokenizer
nltk.download('punkt')

# Preprocess the text: convert to lowercase, remove punctuation, tokenize
def preprocess_text(text):
    text = text.lower()
    text = text.translate(str.maketrans('', '', string.punctuation))
    tokens = word_tokenize(text)
    return tokens

# Preprocess the data
df["Business Process 1"] = df["Business Process 1"].apply(lambda bp: [preprocess_text(activity) for activity in bp])
df["Business Process 2"] = df["Business Process 2"].apply(lambda bp: [preprocess_text(activity) for activity in bp])
df["Obligation"] = df["Obligation"].apply(preprocess_text)

df.head()

# Convert list in each cell to string for metadata generation and mapping
df_str = df.copy()
df_str["Business Process 1"] = df_str["Business Process 1"].apply(str)
df_str["Business Process 2"] = df_str["Business Process 2"].apply(str)
df_str["Obligation"] = df_str["Obligation"].apply(str)

# Generate metadata for each column
metadata = {
    "Business Process 1": {
        "num_unique_values": df_str["Business Process 1"].nunique(),
        "example_value": df_str["Business Process 1"].iloc[0],
    },
    "Business Process 2": {
        "num_unique_values": df_str["Business Process 2"].nunique(),
        "example_value": df_str["Business Process 2"].iloc[0],
    },
    "Obligation": {
        "num_unique_values": df_str["Obligation"].nunique(),
        "example_value": df_str["Obligation"].iloc[0],
    },
}

# Generate a mapping from Business Process 1 to Business Process 2 to Obligation
mapping = df_str.groupby(["Business Process 1", "Business Process 2"])["Obligation"].apply(list).reset_index()

# Save the mapping to a CSV file
mapping.to_csv("mapping.csv", index=False)

metadata, mapping.head()

# Generate unique IDs for Business Process 1 and Business Process 2
df_str['ID1'] = range(1, len(df_str) + 1)
df_str['ID2'] = range(len(df_str) + 1, (2 * len(df_str)) + 1)

# Generate metadata for each column
metadata = {
    "ID1": {
        "num_unique_values": df_str["ID1"].nunique(),
        "example_value": df_str["ID1"].iloc[0],
    },
    "Business Process 1": {
        "num_unique_values": df_str["Business Process 1"].nunique(),
        "example_value": df_str["Business Process 1"].iloc[0],
    },
    "ID2": {
        "num_unique_values": df_str["ID2"].nunique(),
        "example_value": df_str["ID2"].iloc[0],
    },
    "Business Process 2": {
        "num_unique_values": df_str["Business Process 2"].nunique(),
        "example_value": df_str["Business Process 2"].iloc[0],
    },
    "Obligation": {
        "num_unique_values": df_str["Obligation"].nunique(),
        "example_value": df_str["Obligation"].iloc[0],
    },
}

# Generate a mapping from Business Process 1 to Business Process 2 to Obligation
mapping = df_str.groupby(["ID1", "Business Process 1", "ID2", "Business Process 2"])["Obligation"].apply(list).reset_index()

# Save the mapping to a CSV file
mapping.to_csv("mapping_with_ids.csv", index=False)

metadata, mapping.head()

import pandas as pd

# Load the data
data_path = "mapping_with_ids.csv"
data = pd.read_csv(data_path)

# Display the first few rows of the data
data.head()

from ast import literal_eval

# Convert string representation of lists into actual lists
data['Business Process 1'] = data['Business Process 1'].apply(literal_eval)
data['Business Process 2'] = data['Business Process 2'].apply(literal_eval)
data['Obligation'] = data['Obligation'].apply(literal_eval)

# Display the first few rows of the data after conversion
data.head()

from itertools import combinations
from tqdm import tqdm

# Flatten the sentences in each business process and obligation
data['Business Process 1'] = data['Business Process 1'].apply(lambda x: ' '.join([' '.join(sent) for sent in x]))
data['Business Process 2'] = data['Business Process 2'].apply(lambda x: ' '.join([' '.join(sent) for sent in x]))
data['Obligation'] = data['Obligation'].apply(lambda x: ' '.join([' '.join(sent) for sent in x]))

# Create a list to store the pairs
pairs = []

# Create all unique pairs of business processes
for _, row1 in tqdm(data.iterrows(), total=data.shape[0]):
    for _, row2 in data.iterrows():
        if row1['ID1'] != row2['ID1']:
            # Compare the obligations to determine similarity
            similar = int(row1['Obligation'] == row2['Obligation'])
            pairs.append([row1['Business Process 1'], row2['Business Process 2'], similar])

# Create a new DataFrame with the pairs and their similarity labels
pairs_df = pd.DataFrame(pairs, columns=['Business Process 1', 'Business Process 2', 'Similar'])

# Display the first few rows of the pairs DataFrame
pairs_df.head()

!pip install transformers

from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments
from sklearn.model_selection import train_test_split
import torch

# Initialize the tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Tokenize the pairs of business processes
encoded_pairs = tokenizer(pairs_df['Business Process 1'].tolist(), pairs_df['Business Process 2'].tolist(), truncation=True, padding=True)

# Create input tensors
input_ids = torch.tensor(encoded_pairs['input_ids'])
attention_mask = torch.tensor(encoded_pairs['attention_mask'])
labels = torch.tensor(pairs_df['Similar'].tolist())

# Split the data into training and validation sets
train_inputs, val_inputs, train_labels, val_labels, train_masks, val_masks = train_test_split(input_ids, labels, attention_mask, test_size=0.1)

# Initialize the model
model = BertForSequenceClassification.from_pretrained('bert-base-uncased')

# Define the training arguments
training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=3,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=64,
    warmup_steps=500,
    weight_decay=0.01,
)

# Initialize the trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_inputs,
    eval_dataset=val_inputs
)

# Train the model
trainer.train()

# Evaluate the model
trainer.evaluate()

from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score
import numpy as np

# Apply the model to the validation data
outputs = model(val_inputs)

# Apply softmax to the outputs to get the probabilities
probs = torch.nn.functional.softmax(outputs.logits, dim=-1)

# Compute the similarity scores and applicability scores
similarity_scores = probs[:, 1] # Probability that the processes are similar
applicability_scores = torch.max(probs, dim=-1).values

# Compute the predicted labels (choose the class with the highest probability)
preds = torch.argmax(outputs.logits, dim=-1)

# Compute the recall, precision, and F1-score
recall = recall_score(val_labels, preds)
precision = precision_score(val_labels, preds)
f1 = f1_score(val_labels, preds)

# Compute the AUC
auc = roc_auc_score(val_labels, similarity_scores)

# Print the metrics
print(f"Recall: {recall}")
print(f"Precision: {precision}")
print(f"F1-score: {f1}")
print(f"AUC: {auc}")


from sklearn.metrics import accuracy_score

# Compute the predicted labels
preds = torch.argmax(outputs.logits, dim=-1)

# Compute the accuracy
accuracy = accuracy_score(val_labels, preds)

print(f"Accuracy: {accuracy}")

"""Recall (also known as sensitivity) is the proportion of actual positives that are correctly identified as such.
Precision is the proportion of positive identifications that are actually correct.
The F1 score is the harmonic mean of precision and recall, and it gives a balance between these two metrics.
AUC is a comprehensive metric that considers all possible classification thresholds. An AUC of 1.0 indicates perfect classification, while an AUC of 0.5 indicates that the model is no better than random chance.




"""

from transformers import TransfoXLTokenizer, TransfoXLModel

tokenizer = TransfoXLTokenizer.from_pretrained('transfo-xl-wt103')
model = TransfoXLModel.from_pretrained('transfo-xl-wt103')

from transformers import BertTokenizer, BertForSequenceClassification
from transformers import RobertaTokenizer, RobertaForSequenceClassification
from transformers import DistilBertTokenizer, DistilBertForSequenceClassification

# Choose the model you want to use
model_name = 'bert'  # Change this to 'roberta' or 'distilbert' to use those models

if model_name == 'bert':
    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
    model = BertForSequenceClassification.from_pretrained('bert-base-uncased')
elif model_name == 'roberta':
    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')
    model = RobertaForSequenceClassification.from_pretrained('roberta-base')
elif model_name == 'distilbert':
    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')
else:
    print(f"Unsupported model: {model_name}")

from transformers import TransfoXLTokenizer, TransfoXLModel
from torch import nn
from torch.utils.data import Dataset, DataLoader
from torch.optim import AdamW
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Initialize the Transformer-XL tokenizer and model
tokenizer = TransfoXLTokenizer.from_pretrained('transfo-xl-wt103')
model = nn.Sequential(
    TransfoXLModel.from_pretrained('transfo-xl-wt103'),
    nn.Linear(model.d_model, 2)  # Add a classification head with 2 output classes
)

# Tokenize the pairs of business processes
inputs = tokenizer(pairs_df['Business Process 1'].tolist(), pairs_df['Business Process 2'].tolist(), truncation=True, padding=True, max_length=512, return_tensors='pt')

# Prepare the labels
labels = torch.tensor(pairs_df['Similar'].tolist())

# Split the data into training and validation sets
train_inputs, val_inputs, train_labels, val_labels = train_test_split(inputs, labels, test_size=0.1)

# Create PyTorch Datasets and DataLoaders
class ProcessPairDataset(Dataset):
    def __init__(self, inputs, labels):
        self.inputs = inputs
        self.labels = labels

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        return self.inputs[idx], self.labels[idx]

train_dataset = ProcessPairDataset(train_inputs, train_labels)
val_dataset = ProcessPairDataset(val_inputs, val_labels)

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)

# Define the optimizer
optimizer = AdamW(model.parameters(), lr=1e-5)

# Train the model
for epoch in range(num_epochs):
    for inputs, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = nn.CrossEntropyLoss()(outputs, labels)  # Compute the loss
        loss.backward()  # Perform backpropagation
        optimizer.step()  # Update the weights

# Evaluate the model
correct = 0
total = 0
for inputs, labels in val_loader:
    outputs = model(inputs)
    preds = torch.argmax(outputs, dim=1)  # Get the predicted labels
    correct += (preds == labels).sum().item()
    total += labels.size(0)

accuracy = correct / total
print(f"Accuracy: {accuracy}")

from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix
import numpy as np

# Apply the model to the validation data
outputs = model(val_inputs)

# Apply softmax to the outputs to get the probabilities
probs = torch.nn.functional.softmax(outputs.logits, dim=-1)

# Compute the predicted labels (choose the class with the highest probability)
preds = torch.argmax(outputs.logits, dim=-1)

# Compute the recall, precision, and F1-score
recall = recall_score(val_labels, preds)
precision = precision_score(val_labels, preds)
f1 = f1_score(val_labels, preds)

# Compute the AUC
auc = roc_auc_score(val_labels, probs[:, 1])

# Compute the confusion matrix
cm = confusion_matrix(val_labels, preds)

# Print the metrics and confusion matrix
print(f"Recall: {recall}")
print(f"Precision: {precision}")
print(f"F1-score: {f1}")
print(f"AUC: {auc}")
print(f"Confusion Matrix:\n{cm}")









